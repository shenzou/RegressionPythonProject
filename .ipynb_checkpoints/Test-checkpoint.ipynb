{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!sudo pip3 install pandas\n",
    "#!sudo pip3 install sklearn\n",
    "#!sudo pip3 install graphviz\n",
    "#!sudo pip3 install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Traitement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importation du dataset contenant les données débloatées \n",
    "(Plusieurs colonnes normalisées (caller_id, opened_by, sys_created_by, sys_updated_by, location, category, subcategory, u_symptom, cmdb_ci, assignement_group, assigned_to, problem_id, rfc, vendor, closed_code, resolved_by ne contiennent plus que des valeurs numériques, sans perte d'information). Les \"?\" ont été remplacés par des cases vides. \n",
    "De plus, les variables de type object ou string ont été converties en float ou int, suivant le cas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#La colonne \"caused_by\" a été supprimée car vide\n",
    "dataset = pd.read_csv(\"incident_event_log_debloated.csv\", sep=',', encoding='UTF-8')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Conversion des types de données erronés\n",
    "On va supprimer certaines colonnes qui sont inutiles pour notre régression, comme l'ID de l'incident et le RFC.\n",
    "Pandas a également mal interprété le type de données de certaines colonnes, on applique donc une correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(columns=\"rfc\")\n",
    "dataset.active = dataset.active.astype(int)\n",
    "dataset.made_sla = dataset.made_sla.astype(int)\n",
    "print(dataset.incident_state.value_counts())\n",
    "incident_state_dico = {\"New\":0, \"Resolved\":1, \"Closed\":2, \"Active\":3, \"Awaiting User Info\":4, \"Awaiting Vendor\":5, \"Awaiting Problem\":6, \"Awaiting Evidence\":7, \"-100\":8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dataset.replace({\"incident_state\": incident_state_dico})\n",
    "dataset.incident_state = dataset.incident_state.map(incident_state_dico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.contact_type.value_counts())\n",
    "contact_type_dico = {\"Phone\":0, \"Self service\":1, \"Email\":2, \"IVR\":3, \"Direct opening\":4}\n",
    "dataset.contact_type = dataset.contact_type.map(contact_type_dico)\n",
    "dataset.contact_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.impact.value_counts())\n",
    "impact_dico = {\"2 - Medium\":2, \"3 - Low\":3, \"1 - High\":1}\n",
    "dataset.impact = dataset.impact.map(impact_dico)\n",
    "dataset.urgency = dataset.urgency.map(impact_dico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.priority.value_counts())\n",
    "priority_dico = {\"3 - Moderate\":3, \"4 - Low\":4, \"2 - High\":2, \"1 - Critical\":1}\n",
    "dataset.priority = dataset.priority.map(priority_dico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.knowledge = dataset.knowledge.astype(int)\n",
    "dataset.u_priority_confirmation = dataset.u_priority_confirmation.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.notify.value_counts())\n",
    "notify_dico = {\"Do Not Notify\":0, \"Send Email\":1}\n",
    "dataset.notify = dataset.notify.map(notify_dico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.vendor.value_counts())\n",
    "vendor_dico = {\"8s\":0, \"Vendor 1\":1, \"Vendor 2\":2, \"Vendor 3\":3}\n",
    "dataset.vendor = dataset.vendor.map(vendor_dico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. On cherche le temps de résolution pour chaque ligne\n",
    "Pour chaque ligne, on calcule la différence de temps entre la résolution et l'ouverture de l'incident. Ces informations sont rangées dans une liste de la même longueur que le dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_list = list()\n",
    "def resolved_time(row):    \n",
    "    cols = ['opened_at','closed_at']\n",
    "    #cols = ['opened_at','resolved_at']\n",
    "    opened_at = pd.to_datetime(row[cols[0]])\n",
    "    closed_at = pd.to_datetime(row[cols[1]])\n",
    "    #resolved_at = pd.to_datetime(row[cols[1]])\n",
    "    \n",
    "    time_completion = (closed_at - opened_at)\n",
    "    #time_completion = (resolved_at - opened_at)\n",
    "    \n",
    "    #if time_completion > datetime.timedelta(seconds=0): \n",
    "    #    Y_list.append(time_completion)\n",
    "    #else:\n",
    "    #    Y_list.append(-1)\n",
    "    Y_list.append(time_completion)\n",
    "    \n",
    "    \n",
    "for index, row in dataset.iterrows():\n",
    "    resolved_time(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Y_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. On controle s'il y a des valeurs négatives. Nous allons donc remplacer ces valeurs négatives par \"-1\" afin d'avoir des données logiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "minutesList = list()\n",
    "length = len(dataset) \n",
    "for i in range(length):\n",
    "    if Y_list[i] > datetime.timedelta(seconds=0):\n",
    "        minutesList.append(Y_list[i].total_seconds()/60)\n",
    "    else:\n",
    "        minutesList.append(-1)\n",
    "\n",
    "duration = np.ravel(pd.DataFrame(minutesList))\n",
    "duration[:20]\n",
    "dataset[\"resolved_in\"] = duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(columns=\"number\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. On garde seulement les incidents ayant pour statut \"Closed\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "resolved_temp = dataset.loc[dataset.incident_state == 2]\n",
    "dataset = pd.DataFrame(resolved_temp)\n",
    "dataset = dataset.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On garde seulement les lignes ayant une valeur correcte pour resolved_in"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "resolved_temp = dataset.loc[dataset.resolved_in != -1]\n",
    "dataset = pd.DataFrame(resolved_temp)\n",
    "dataset = dataset.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après avoir trouvé ces temps, on va convertir les colonnes de type date (en string) en float."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "dataset.opened_at = dataset.opened_at.str.replace(\"/\",\"\")\n",
    "dataset.sys_created_at = dataset.sys_created_at.str.replace(\"/\",\"\")\n",
    "dataset.sys_updated_at = dataset.sys_updated_at.str.replace(\"/\",\"\")\n",
    "dataset.resolved_at = dataset.resolved_at.str.replace(\"/\",\"\")\n",
    "dataset.closed_at = dataset.closed_at.str.replace(\"/\",\"\")\n",
    "\n",
    "dataset.opened_at = dataset.opened_at.str.replace(\" \",\"\")\n",
    "dataset.sys_created_at = dataset.sys_created_at.str.replace(\" \",\"\")\n",
    "dataset.sys_updated_at = dataset.sys_updated_at.str.replace(\" \",\"\")\n",
    "dataset.resolved_at = dataset.resolved_at.str.replace(\" \",\"\")\n",
    "dataset.closed_at = dataset.closed_at.str.replace(\" \",\"\")\n",
    "\n",
    "dataset.opened_at = dataset.opened_at.str.replace(\":\",\"\")\n",
    "dataset.sys_created_at = dataset.sys_created_at.str.replace(\":\",\"\")\n",
    "dataset.sys_updated_at = dataset.sys_updated_at.str.replace(\":\",\"\")\n",
    "dataset.resolved_at = dataset.resolved_at.str.replace(\":\",\"\")\n",
    "dataset.closed_at = dataset.closed_at.str.replace(\":\",\"\")\n",
    "\n",
    "dataset.opened_at = dataset.opened_at.astype(float)\n",
    "dataset.sys_created_at = dataset.sys_created_at.astype(float)\n",
    "dataset.sys_updated_at = dataset.sys_updated_at.astype(float)\n",
    "dataset.resolved_at = dataset.resolved_at.astype(float)\n",
    "dataset.closed_at = dataset.closed_at.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.opened_at = pd.to_datetime(dataset.opened_at, errors='coerce')\n",
    "dataset.sys_created_at = pd.to_datetime(dataset.sys_created_at, errors='coerce')\n",
    "dataset.sys_updated_at = pd.to_datetime(dataset.sys_updated_at, errors='coerce')\n",
    "dataset.resolved_at = pd.to_datetime(dataset.resolved_at, errors='coerce')\n",
    "dataset.closed_at = pd.to_datetime(dataset.closed_at, errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. On regarde si certaines colonnes ont trop de valeurs manquantes (et ne sont donc pas utilisables). Si plus de 30% des données de la colonne sont manquantes, on la supprime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "total = len(dataset[\"incident_state\"])\n",
    "#print(dataset[\"vendor\"][3])\n",
    "for column in dataset.columns:\n",
    "    v = 0\n",
    "    for i in range(total):\n",
    "        if dataset[column][i] == None:\n",
    "            v+=1\n",
    "        elif dataset[column].dtype == int or dataset[column].dtype == float:\n",
    "            if math.isnan(dataset[column][i]):\n",
    "                v+=1\n",
    "    if v/total*100 > 30:\n",
    "        print(\"Column name: \", column, \" ; Empty: \", v/total*100, \"%\")\n",
    "        dataset = dataset.drop(columns=column)\n",
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backup = dataset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Pour restaurer le dataset en cas de problème"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = backup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Régressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Si on a des valeurs infinies dans le dataset, elles sont remplacées par NaN. Ensuite, les valeurs NaN du dataset sont remplacées par une moyenne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "dataset[dataset==np.inf]=np.nan\n",
    "dataset.fillna(dataset.mean(), inplace=True)\n",
    "\n",
    "#for i in range(len(dataset['sys_updated_at'])):\n",
    "#    dataset.sys_updated_at[i] = datetime.timestamp(dataset.sys_updated_at[i])\n",
    "#dataset.sys_updated_at = datetime.timestamp(dataset.sys_updated_at)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. On crée nos X et Y en supprimant les colonnes nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset.resolved_in\n",
    "x = dataset.drop('resolved_in', axis=1)\n",
    "x = x.drop('resolved_at', axis=1)\n",
    "x = x.drop('closed_at', axis=1)\n",
    "x = x.drop('opened_at', axis=1)\n",
    "x = x.drop('sys_created_at', axis = 1)\n",
    "x = x.drop('sys_updated_at', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "heat = dataset.drop('resolved_at', axis=1)\n",
    "heat = heat.drop('closed_at', axis=1)\n",
    "heat = heat.drop('opened_at', axis=1)\n",
    "heat = heat.drop('sys_created_at', axis = 1)\n",
    "heat = heat.drop('sys_updated_at', axis=1)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "corr = heat.corr()\n",
    "sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "            square=True, ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x[['caller_id', 'location', 'resolved_by', 'opened_by']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. On sépare nos données en un dataset de train et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x,y,test_size=0.2, random_state=0)\n",
    "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. On réinitialise les index de test afin de pouvoir avoir des plots propres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.reset_index(drop=True)\n",
    "Y_test = Y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test pour déterminer les variables donnant le meilleur score."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "progress = 0\n",
    "newX = x\n",
    "bestScore = 0\n",
    "regress = DecisionTreeRegressor\n",
    "for var1 in range(len(x.columns)):\n",
    "    for var2 in range(len(x.columns)):\n",
    "        progress+=1\n",
    "        pr = progress/576*100\n",
    "        print(pr, '%')\n",
    "        \n",
    "        for var3 in range(len(x.columns)):\n",
    "            for var4 in range(len(x.columns)):\n",
    "                newX = x.iloc[: , [var1, var2, var3, var4]]\n",
    "                \n",
    "                X_train, X_test, Y_train, Y_test = train_test_split(newX,y,test_size=0.2, random_state=0)\n",
    "                X_train.shape, X_test.shape, Y_train.shape, Y_test.shape\n",
    "                regressor = DecisionTreeRegressor()\n",
    "                regressor.fit(X_train, Y_train)\n",
    "                if regressor.score(X_test, Y_test) > bestScore:\n",
    "                    bestScore = regressor.score(X_test, Y_test)\n",
    "                    regress = regressor\n",
    "                    print(bestScore)\n",
    "                    print(newX[: 1])\n",
    "print(bestScore)\n",
    "newX\n",
    "#x = x[['knowledge', 'sys_mod_count', 'reassignment_count', 'resolved_by', 'assigned_to']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimisation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, cross_val_predict, train_test_split\n",
    "\n",
    "dtm = DecisionTreeRegressor(max_depth=4,\n",
    "                           min_samples_split=5,\n",
    "                           max_leaf_nodes=10)\n",
    "\n",
    "dtm.fit(X_train,Y_train)\n",
    "print(\"R-Squared on train dataset={}\".format(dtm.score(X_test,Y_test)))\n",
    "\n",
    "dtm.fit(X_test,Y_test)   \n",
    "print(\"R-Squaredon test dataset={}\".format(dtm.score(X_test,Y_test)))\n",
    "\n",
    "param_grid = {\"criterion\": [\"mse\", \"mae\"],\n",
    "              \"min_samples_split\": [10, 20, 40],\n",
    "              \"max_depth\": [2, 6, 8],\n",
    "              \"min_samples_leaf\": [20, 40, 100],\n",
    "              \"max_leaf_nodes\": [5, 20, 100],\n",
    "              }\n",
    "\n",
    "grid_cv_dtm = GridSearchCV(dtm, param_grid, cv=5, n_jobs=4)\n",
    "\n",
    "grid_cv_dtm.fit(X_train,Y_train)\n",
    "\n",
    "print(\"R-Squared::{}\".format(grid_cv_dtm.best_score_))\n",
    "print(\"Best Hyperparameters::\\n{}\".format(grid_cv_dtm.best_params_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meilleurs paramètres trouvés:\n",
    "{'criterion': 'mse', 'max_depth': 6, 'max_leaf_nodes': 100, 'min_samples_leaf': 20, 'min_samples_split': 10}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Scaling"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "#regressor = DecisionTreeRegressor(criterion='mse', max_depth=6, max_leaf_nodes=100, min_samples_leaf=20, min_samples_split=10)\n",
    "regressor = DecisionTreeRegressor()\n",
    "#cross_val_score(regressor, X_train, Y_train, cv=10)\n",
    "regressor.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.Series(regressor.feature_importances_, index=X_train.columns)\n",
    "importances.nlargest(20).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "regressor.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'Actual':Y_test, 'Predicted':y_pred})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(Y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(Y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(Y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X_test.index[2000:2100], Y_test[2000:2100], s=20, edgecolor=\"black\",\n",
    "            c=\"darkorange\", label=\"original data\")\n",
    "plt.plot(X_test.index[2000:2100], y_pred[2000:2100], color=\"cornflowerblue\",\n",
    "         label=\"prediction\", linewidth=1)\n",
    "plt.xlabel(\"data\")\n",
    "plt.ylabel(\"Resolution time\")\n",
    "plt.title(\"Decision Tree Regression\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Random Forest Regressor"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, cross_val_predict, train_test_split, RandomizedSearchCV\n",
    "\n",
    "\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 1500, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "rfr = RandomForestRegressor()\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = rfr, param_distributions = random_grid, n_iter = 50, cv = 2, verbose=5, random_state=42, n_jobs = 4)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "print(\"R-Squared::{}\".format(rf_random.best_score_))\n",
    "print(\"Best Hyperparameters::\\n{}\".format(rf_random.best_params_))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "R-Squared::0.21366126150335107\n",
    "Best Hyperparameters::\n",
    "{'n_estimators': 600, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 110, 'bootstrap': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "\n",
    "#randomForestRegressor = RandomForestRegressor(n_estimators=600, min_samples_split=2, min_samples_leaf=2, max_features='sqrt', max_depth=110, bootstrap=False, random_state=100)\n",
    "randomForestRegressor = RandomForestRegressor()\n",
    "randomForestRegressor.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.Series(randomForestRegressor.feature_importances_, index=X_train.columns)\n",
    "importances.nlargest(20).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomForestRegressor.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yRFR = randomForestRegressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'Actual':Y_test, 'Predicted':yRFR})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(Y_test, yRFR))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(Y_test, yRFR))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(Y_test, yRFR)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X_test.index[2131:2180], Y_test[2131:2180], s=20, edgecolor=\"black\",\n",
    "            c=\"darkorange\", label=\"original data\")\n",
    "plt.plot(X_test.index[2131:2180], yRFR[2131:2180], color=\"cornflowerblue\",\n",
    "         label=\"prediction\", linewidth=1)\n",
    "plt.xlabel(\"data\")\n",
    "plt.ylabel(\"Resolution time\")\n",
    "plt.title(\"Random Forest Regressor\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Support Vector Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVR Linear (Ne fonctionne pas)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.svm import SVR\n",
    "#import numpy as np\n",
    "svrRegressor = SVR()\n",
    "svrRegressor.fit(X_train,Y_train)\n",
    "ySVR = svrRegressor.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "importances = pd.Series(svrRegressor.feature_importances_, index=X_train.columns)\n",
    "importances.nlargest(20).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "svrRegressor.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df=pd.DataFrame({'Actual':Y_test, 'Predicted':ySVR})\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X_test.index[2131:2180], Y_test[2131:2180], s=20, edgecolor=\"black\",\n",
    "            c=\"darkorange\", label=\"original data\")\n",
    "plt.plot(X_test.index[2131:2180], ySVR[2131:2180], color=\"cornflowerblue\",\n",
    "         label=\"prediction \", linewidth=1)\n",
    "plt.xlabel(\"data\")\n",
    "plt.ylabel(\"Resolution time\")\n",
    "plt.title(\"Support vector regressor\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVR RBF"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.svm import SVR\n",
    "rbfRegressor = SVR(kernel='rbf', epsilon=1.0)\n",
    "rbfRegressor.fit(X_train, Y_train)\n",
    "yRBF = rbfRegressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "rbfRegressor.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df=pd.DataFrame({'Actual':Y_test, 'Predicted':yRBF})\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X_test.index[2131:2180], Y_test[2131:2180], s=20, edgecolor=\"black\",\n",
    "            c=\"darkorange\", label=\"original data\")\n",
    "plt.plot(X_test.index[2131:2180], yRBF[2131:2180], color=\"cornflowerblue\",\n",
    "         label=\"prediction \", linewidth=1)\n",
    "plt.xlabel(\"data\")\n",
    "plt.ylabel(\"Resolution time\")\n",
    "plt.title(\"Support vector regressor (RBF)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. AdaBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "adaBoostRegressor = AdaBoostRegressor(n_estimators=150,random_state=0)\n",
    "#adaBoostRegressor = AdaBoostRegressor()\n",
    "adaBoostRegressor.fit(X_train,Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.Series(adaBoostRegressor.feature_importances_, index=X_train.columns)\n",
    "importances.nlargest(20).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaBoostRegressor.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yAda = adaBoostRegressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'Actual':Y_test, 'Predicted':yAda})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X_test.index[2131:2180], Y_test[2131:2180], s=20, edgecolor=\"black\",\n",
    "            c=\"darkorange\", label=\"original data\")\n",
    "plt.plot(X_test.index[2131:2180], yAda[2131:2180], color=\"cornflowerblue\",\n",
    "         label=\"prediction\", linewidth=1)\n",
    "plt.xlabel(\"data\")\n",
    "plt.ylabel(\"Resolution time\")\n",
    "plt.title(\"AdaBoost Regressor\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. GradientBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gradientBoostRegressor = GradientBoostingRegressor(random_state=1, n_estimators=150)\n",
    "#gradientBoostRegressor = GradientBoostingRegressor()\n",
    "gradientBoostRegressor.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.Series(gradientBoostRegressor.feature_importances_, index=X_train.columns)\n",
    "importances.nlargest(20).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradientBoostRegressor.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yGrad = gradientBoostRegressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'Actual':Y_test, 'Predicted':yGrad})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X_test.index[2131:2180], Y_test[2131:2180], s=20, edgecolor=\"black\",\n",
    "            c=\"darkorange\", label=\"original data\")\n",
    "plt.plot(X_test.index[2131:2180], yGrad[2131:2180], color=\"cornflowerblue\",\n",
    "         label=\"prediction\", linewidth=1)\n",
    "plt.xlabel(\"data\")\n",
    "plt.ylabel(\"Resolution time\")\n",
    "plt.title(\"GradientBoost Regressor\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Linear Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linearRegressor = LinearRegression()\n",
    "linearRegressor.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.Series(linearRegressor.singular_, index=X_train.columns)\n",
    "importances.nlargest(20).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linearRegressor.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linGrad = linearRegressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'Actual':Y_test, 'Predicted':linGrad})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X_test.index[2131:2180], Y_test[2131:2180], s=20, edgecolor=\"black\",\n",
    "            c=\"darkorange\", label=\"original data\")\n",
    "plt.plot(X_test.index[2131:2180], linGrad[2131:2180], color=\"cornflowerblue\",\n",
    "         label=\"prediction\", linewidth=1)\n",
    "plt.xlabel(\"data\")\n",
    "plt.ylabel(\"Resolution time\")\n",
    "plt.title(\"GradientBoost Regressor\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Résultats finaux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Comparaison des différents modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X_test.index[2131:2145], Y_test[2131:2145], s=20, edgecolor=\"black\",\n",
    "            c=\"darkorange\", label=\"original data\")\n",
    "plt.plot(X_test.index[2131:2145], y_pred[2131:2145], color=\"red\",\n",
    "         label=\"prediction Decision Tree Regressor\", linewidth=1)\n",
    "plt.plot(X_test.index[2131:2145], yRFR[2131:2145], color=\"cornflowerblue\",\n",
    "         label=\"prediction Random Forest Regressor\", linewidth=1)\n",
    "#plt.plot(X_test.index[2131:2145], yRBF[2131:2145], color=\"green\",\n",
    "#         label=\"prediction RBF Regressor\", linewidth=1)\n",
    "plt.plot(X_test.index[2131:2145], yAda[2131:2145], color=\"purple\",\n",
    "         label=\"prediction AdaBoost Regressor\", linewidth=1)\n",
    "plt.plot(X_test.index[2131:2145], yGrad[2131:2145], color=\"yellow\",\n",
    "         label=\"prediction GradientBoost Regressor\", linewidth=1)\n",
    "plt.plot(X_test.index[2131:2145], linGrad[2131:2145], color=\"green\",\n",
    "         label=\"prediction Linear Regressor\", linewidth=1)\n",
    "plt.xlabel(\"data\")\n",
    "plt.ylabel(\"Resolution time\")\n",
    "plt.title(\"Decision Tree Regression\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur ce graphe assez réduit, DecisionTreeRegressor et RandomForestRegressor ont les résultats les plus proches de la réalité."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparons les scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Decision Tree Regressor: \", regressor.score(X_test, Y_test))\n",
    "print(\"Random Forest Regressor: \", randomForestRegressor.score(X_test, Y_test))\n",
    "#print(\"RBF Regressor: \", rbfRegressor.score(X_test, Y_test))\n",
    "print(\"AdaBoost Regressor: \", adaBoostRegressor.score(X_test, Y_test))\n",
    "print(\"GradientBoost Regressor: \", gradientBoostRegressor.score(X_test, Y_test))\n",
    "print(\"Linear Regressor: \", linearRegressor.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ces résultats viennent confirmer le ressenti du graphe: Les scores les plus élevés sont Random Forest et Decision Tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Liaison API"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Exécuter la commande ci-dessous en cas de mise à jour du modèle"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import pickle\n",
    "pickl = {\n",
    "    'randomForest': randomForestRegressor,\n",
    "    'decisionTree': regressor\n",
    "}\n",
    "pickle.dump( pickl, open( 'models' + \".p\", \"wb\" ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
